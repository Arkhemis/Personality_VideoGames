{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ad498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timezone\n",
    "import chime\n",
    "import logging\n",
    "# --- Configuration ---\n",
    "load_dotenv() # Charge les variables depuis le fichier .env\n",
    "\n",
    "CLIENT_ID = os.getenv(\"IGDB_CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"IGDB_CLIENT_SECRET\")\n",
    "DATA_DUMP_DIR = Path('igdb_datadumps') \n",
    "TOKEN_URL = 'https://id.twitch.tv/oauth2/token'\n",
    "API_BASE_URL = 'https://api.igdb.com/v4'\n",
    "\n",
    "DATA_DUMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_api_headers(client_id, client_secret):\n",
    "    \"\"\"Récupère un token d'accès Twitch/IGDB.\"\"\"\n",
    "    print(\"Récupération du token d'accès Twitch...\")\n",
    "    if not client_id or not client_secret:\n",
    "        print(\"ERREUR: CLIENT_ID ou CLIENT_SECRET manquant.\")\n",
    "        return None\n",
    "    try:\n",
    "        response = requests.post(TOKEN_URL, params={\n",
    "            'client_id': client_id, 'client_secret': client_secret,\n",
    "            'grant_type': 'client_credentials'\n",
    "        }, timeout=15) # Timeout légèrement augmenté\n",
    "        token_data = response.json()\n",
    "        access_token = token_data.get('access_token')\n",
    "        api_headers = {\n",
    "        'Client-ID': CLIENT_ID,\n",
    "        'Authorization': f'Bearer {access_token}',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "        return api_headers\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Erreur lors de la récupération du token : {e}\")\n",
    "\n",
    "\n",
    "REQUIRED_ENDPOINTS = [\n",
    "    'games',  'themes', 'keywords', 'player_perspectives', 'external_games'\n",
    "    # 'genres', 'platforms', 'game_modes'\n",
    "    #  'collections', 'franchises', 'game_types',\n",
    "    # 'game_statuses', 'involved_companies', 'companies', ,\n",
    "    # 'popularity_primitives', 'covers', 'artworks',\n",
    "    # 'screenshots', 'alternative_names', 'external_game_sources',\n",
    "    # 'websites', 'website_types',\n",
    "    # # Ajouts pour les mappings nécessaires\n",
    "    # 'game_localizations',\n",
    "    # #'language_supports',\n",
    "    # 'languages', \n",
    "    # 'multiplayer_modes',\n",
    "    # 'age_ratings',\n",
    "    # 'release_dates', # Absolument nécessaire pour le calcul de release_date min\n",
    "    # 'tags',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_available_dumps(headers):\n",
    "    \"\"\"Récupère la liste des data dumps disponibles depuis l'API.\"\"\"\n",
    "    print(\"Récupération de la liste des data dumps disponibles...\")\n",
    "    if not headers: return None\n",
    "    try:\n",
    "        response = requests.get(f'{API_BASE_URL}/dumps', headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        dumps_list = response.json()\n",
    "        print(f\"Liste des dumps obtenue ({len(dumps_list)} dumps trouvés).\")\n",
    "        # Convertit la liste en dictionnaire {endpoint_name: dump_info}\n",
    "        return {dump['endpoint']: dump for dump in dumps_list if 'endpoint' in dump}\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"ERREUR: Timeout lors de la récupération de la liste des dumps.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ERREUR lors de la récupération de la liste des dumps : {e}\", f\"Réponse: {e.response.text}\" if hasattr(e, 'response') and e.response else \"\")\n",
    "    return None\n",
    "\n",
    "def download_dump(url, dest_path):\n",
    "    try:\n",
    "        with requests.get(url, stream=True, timeout=600) as r: # Timeout long pour gros fichiers\n",
    "            r.raise_for_status()\n",
    "            total_size = int(r.headers.get('content-length', 0))\n",
    "            downloaded_size = 0\n",
    "            last_print_time = time.time()\n",
    "            print(f\"  Taille totale: {total_size/1024/1024:.1f} Mo\" if total_size > 0 else \"  Taille inconnue.\")\n",
    "            with open(dest_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192 * 34): # Chunk de 128Ko\n",
    "                    if chunk: # Filtre les keep-alive chunks\n",
    "                        f.write(chunk)\n",
    "                        downloaded_size += len(chunk)\n",
    "                        now = time.time()\n",
    "                        if total_size > 0 and (now - last_print_time > 1): # MAJ toutes les secondes\n",
    "                            percent = (downloaded_size / total_size) * 100\n",
    "                            print(f\"    -> {downloaded_size/1024/1024:.1f} / {total_size/1024/1024:.1f} Mo ({percent:.1f}%)\", end='\\r')\n",
    "                            last_print_time = now\n",
    "            # Assurer que la ligne de progression est effacée\n",
    "            print(' ' * 80, end='\\r')\n",
    "            print(f\"  {dest_path.name} téléchargé avec succès.\")\n",
    "        return True\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"\\n  ERREUR: Timeout pendant le téléchargement de {dest_path.name}.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\n  ERREUR pendant le téléchargement de {dest_path.name} : {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n  ERREUR inconnue pendant le téléchargement de {dest_path.name} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d677db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_download_dump(endpoint, dump_info, headers, local_dir):\n",
    "    \"\"\"Vérifie si un dump local est à jour et le télécharge si nécessaire.\"\"\"\n",
    "    print(f\"\\n--- Vérification Endpoint: {endpoint} ---\")\n",
    "    try: \n",
    "        url = f'{API_BASE_URL}/dumps/{endpoint}'\n",
    "        response = requests.get(url, headers=headers, timeout=20)\n",
    "    except:\n",
    "        logging.error(f'An error occured for this endpoint: {endpoint} ')\n",
    "        sys.exit()\n",
    "    local_file_path = local_dir / (endpoint + '.csv')\n",
    "    \n",
    "    \n",
    "    url = f'{API_BASE_URL}/dumps/{endpoint}'\n",
    "    response = requests.get(url, headers=headers, timeout=20)\n",
    "    s3_url = response.json().get('s3_url')\n",
    "    if s3_url:\n",
    "        # Supprimer l'ancien fichier avant de télécharger le nouveau\n",
    "        if local_file_path.exists():\n",
    "            print(f\"  Suppression de l'ancien fichier {local_file_path.name}...\")\n",
    "            try:\n",
    "                local_file_path.unlink()\n",
    "            except OSError as e_del:\n",
    "                print(f\"  ERREUR lors de la suppression de l'ancien {local_file_path.name}: {e_del}\")\n",
    "\n",
    "        # Lancer le téléchargement\n",
    "        download_dump(s3_url, local_file_path)\n",
    "    else:\n",
    "        print(f\"Impossible d'obtenir l'URL de téléchargement pour '{endpoint}'.\")\n",
    "        return None # Echec\n",
    "\n",
    "    # Si on arrive ici, c'est que needs_download était False\n",
    "    return local_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83aa25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bf9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_31824\\3982449424.py:25: DtypeWarning: Columns (54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  games = pd.read_csv('igdb_datadumps/games.csv')\n",
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_31824\\3982449424.py:26: DtypeWarning: Columns (4,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  external_games = pd.read_csv('igdb_datadumps/external_games.csv')\n",
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_31824\\3982449424.py:32: DtypeWarning: Columns (4,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  external_games = pd.read_csv('igdb_datadumps/external_games.csv')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def convert_ids_to_names(df, column, target_column):\n",
    "    \"\"\"\n",
    "    Convertit ids en noms à partir d'un DataFrame de référence.\n",
    "    \"\"\"\n",
    "    # Dictionnaire id -> nom\n",
    "    reference_df = pd.read_csv(f'igdb_datadumps/{column}.csv')\n",
    "    mapping = reference_df.set_index('id')[target_column].to_dict()\n",
    "    \n",
    "    def convert(value):\n",
    "        if pd.isna(value) or value == '{}':\n",
    "            return None\n",
    "        \n",
    "        # Extraire les IDs et les convertir en noms\n",
    "        ids = [int(x.strip()) for x in str(value).strip('{}').split(',') if x.strip()]\n",
    "        names = [mapping.get(id, f'Unknown_{id}') for id in ids]\n",
    "        return ', '.join(names)\n",
    "    \n",
    "    return df[column].apply(convert)\n",
    "\n",
    "\n",
    "games = pd.read_csv('igdb_datadumps/games.csv')\n",
    "external_games = pd.read_csv('igdb_datadumps/external_games.csv')\n",
    "\n",
    "games['themes'] = convert_ids_to_names(games, 'themes', 'slug')\n",
    "games['keywords'] = convert_ids_to_names(games, 'keywords', 'slug')\n",
    "games['player_perspectives'] = convert_ids_to_names(games, 'player_perspectives', 'slug')\n",
    "\n",
    "external_games = pd.read_csv('igdb_datadumps/external_games.csv')\n",
    "external_games = external_games[external_games['category'] == 1] #Only steam games\n",
    "external_games['appid'] = external_games['url'].str.extract(r'app/(\\d+)')\n",
    "\n",
    "\n",
    "\n",
    "games_with_id = pd.merge(games, external_games, left_on='id', right_on='game')\n",
    "games_with_id = games_with_id[['slug', 'name_x', 'appid', 'summary', 'themes', 'keywords', 'player_perspectives', 'first_release_date', ]]\n",
    "games_clean = games_with_id.rename(columns={'name_x': 'title'})\n",
    "games_clean_sorted = games_clean.sort_values(by=['first_release_date'], ascending=False)\n",
    "games_clean_sorted_deduped = games_clean_sorted.drop_duplicates(subset=['appid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88192b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from models import GameTable\n",
    "from datetime import datetime\n",
    "engine = sqlalchemy.create_engine(\"postgresql://user:password@localhost:5434/steamreviews\")\n",
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "    \n",
    "\n",
    "\n",
    "GameTable.__table__.drop(engine, checkfirst=True)\n",
    "GameTable.__table__.create(engine)\n",
    "for _, row in games_clean_sorted_deduped.iterrows():\n",
    "    if pd.isna(row['appid']):\n",
    "        continue\n",
    "    release_date = None\n",
    "    if pd.notna(row.get('first_release_date')):\n",
    "        try:\n",
    "            # Si c'est une string, la parser\n",
    "            if isinstance(row['first_release_date'], str):\n",
    "                release_date = datetime.strptime(row['first_release_date'], '%Y-%m-%d %H:%M:%S').date()\n",
    "            # Si c'est déjà un datetime\n",
    "            elif hasattr(row['first_release_date'], 'date'):\n",
    "                release_date = row['first_release_date'].date()\n",
    "        except (ValueError, AttributeError):\n",
    "            release_date = None\n",
    "    game = GameTable(\n",
    "        slug=row['slug'],\n",
    "        title=row.get('title'),  \n",
    "        steam_app_id=int(row['appid']),\n",
    "        summary=row.get('summary'),\n",
    "        themes=row.get('themes', '').split(', ') if row.get('themes') else None,\n",
    "        keywords=row.get('keywords', '').split(', ') if row.get('keywords') else None,\n",
    "        player_perspectives=row.get('player_perspectives', '').split(', ') if row.get('player_perspectives') else None,\n",
    "        first_release_date=release_date,\n",
    "    )\n",
    "    session.add(game)\n",
    "\n",
    "session.commit()\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(games_with_id.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a490ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
