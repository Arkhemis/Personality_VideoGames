{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing part\n",
    "import re \n",
    "import string\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import spacy\n",
    "import warnings\n",
    "from gensim.models import CoherenceModel\n",
    "from pprint import pprint\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "from gensim.utils import simple_preprocess\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from lingua import Language, LanguageDetectorBuilder\n",
    "import sqlalchemy\n",
    "from cleantext import clean\n",
    "import chime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#Statistical analysis\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import statsmodels.api as sm\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) #Remove warnings\n",
    "\n",
    "# To replicate results\n",
    "nlp_model = spacy.load('en_core_web_sm')\n",
    "nlp_model.max_length = 1000000000\n",
    "SEED = 1962\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "detector = LanguageDetectorBuilder.from_all_languages.build()\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Récupère les stopwords anglais\n",
    "stopwords = set(stopwords.words('english')).union(['game', 'videogame', 'video game', 'games', 'video games'])\n",
    "engine = sqlalchemy.create_engine(\"postgresql://user:password@localhost:5434/steamreviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd35d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def clean_text(text, stopwords):\n",
    "    text = str(text).lower()  # Lowercase words\n",
    "    text = re.sub(r\"\\[(.*?)\\]\", \"\", text)  # Remove [+XYZ chars] in content\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces in content\n",
    "    text = re.sub(r\"\\w+…|…\", \"\", text)  # Remove ellipsis (and last word)\n",
    "    text = re.sub(r\"<a[^>]*>(.*?)</a>\", r\"\\1\", text) #Remove html tags\n",
    "    text = re.sub(r\"(?<=\\w)-(?=\\w)\", \" \", text)  # Replace dash between words\n",
    "    text = re.sub(\n",
    "        f\"[{re.escape(string.punctuation)}]\", \"\", text\n",
    "    )  # Remove punctuation\n",
    "    doc = nlp_model(text)\n",
    "    tokens = [token.lemma_ for token in doc]\n",
    "    tokens = [t for t in tokens if not t in stopwords and not t.isdigit() and len(t) > 1] #remove short tokens, stopwords and digits\n",
    "    return tokens #Clean the Text\n",
    "\n",
    "\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        language = detector.detect_language_of(text)\n",
    "        return language\n",
    "    except:\n",
    "        logging.error('Failed to identify the language used')\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "df = pd.read_sql(\"\"\"\n",
    "select recommendationid, review_text from games_reviews\n",
    "where regexp_count(trim(review_text), '\\w+')>=5 and playtime_at_review_minutes>120\n",
    "and language = 'english'\n",
    "LIMIT 1000\n",
    "\"\"\", engine)\n",
    "df['detected_language'] = df[df['review_text'].apply(lambda x: detect_lang(x))]\n",
    "vectorizer = np.vectorize(lambda x: clean_text(x, stopwords))\n",
    "df[\"tokens\"] = df[\"review_text\"].apply(lambda x: clean_text(x, stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.models.phrases\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "data_words = df['tokens'].tolist()\n",
    "#del df  # Clear some memory\n",
    "\n",
    "print(\"Création des n-grammes...\")\n",
    "# Création des bigrammes et trigrammes\n",
    "bigram = gensim.models.Phrases(data_words, min_count=10)  # Pas de threshold\n",
    "trigram = gensim.models.Phrases(bigram[data_words])       # Pas de threshold\n",
    "\n",
    "# Votre logique originale (gardant les mots simples + ajoutant n-grammes)\n",
    "for idx in range(len(data_words)):\n",
    "    original_doc = data_words[idx][:]  # Copie\n",
    "    \n",
    "    # Ajouter les bigrammes\n",
    "    for token in bigram[original_doc]:\n",
    "        if '_' in token and token not in data_words[idx]:\n",
    "            data_words[idx].append(token)\n",
    "    \n",
    "    # Ajouter les trigrammes  \n",
    "    for token in trigram[original_doc]:\n",
    "        if '_' in token and token not in data_words[idx]:\n",
    "            data_words[idx].append(token)\n",
    "\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "id2word.filter_extremes(no_below=10, no_above=0.2)\n",
    "corpus = [id2word.doc2bow(text) for text in data_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = lda_model = LdaMulticore(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=20,\n",
    "    random_state=SEED,\n",
    "    workers=4,  # Parallélisation native\n",
    "    passes=10\n",
    ")\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_val = coherencemodel.get_coherence()\n",
    "        coherence_values.append(coherence_val)\n",
    "        print(\"num_topics = \",num_topics, \"has a coherence of:\", coherence_val)\n",
    "\n",
    "    return coherence_values\n",
    "\n",
    "coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_words, start=2, limit=100, step=5)\n",
    "\n",
    "#Plotting the results\n",
    "plt.plot(np.arange(2,20,2), coherence_values[:9], label=\"c\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherenc score\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774aabf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
